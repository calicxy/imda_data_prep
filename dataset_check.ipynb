{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\calic\\Downloads\\imda_data_prep\\env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': {'path': 'C:\\\\Users\\\\calic\\\\Downloads\\\\huggingface-dataset\\\\imda-dataset\\\\IMDA - National Speech Corpus\\\\PART3\\\\tmp_clip.wav', 'array': array([-6.1035156e-05, -3.0517578e-05,  0.0000000e+00, ...,\n",
      "        3.0517578e-05,  3.0517578e-05, -9.1552734e-05], dtype=float32), 'sampling_rate': 16000}, 'transcript': 'start:0, end:24.718', 'mic': None, 'audio_name': None}\n",
      "{'audio': {'path': 'C:\\\\Users\\\\calic\\\\Downloads\\\\huggingface-dataset\\\\imda-dataset\\\\IMDA - National Speech Corpus\\\\PART3\\\\tmp_clip.wav', 'array': array([-6.1035156e-05, -3.0517578e-05,  0.0000000e+00, ...,\n",
      "        3.0517578e-05,  3.0517578e-05, -9.1552734e-05], dtype=float32), 'sampling_rate': 16000}, 'transcript': 'start:0, end:24.718', 'mic': None, 'audio_name': None}\n"
     ]
    }
   ],
   "source": [
    "data = datasets.load_dataset('./loadingScript_imda_part3.py', 'all', split=\"train\", streaming=True)\n",
    "\n",
    "print(next(iter(data)))\n",
    "print(next(iter(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mIPython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdisplay\u001b[39;00m \u001b[39mimport\u001b[39;00m Audio, display\n\u001b[0;32m      3\u001b[0m index \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mshuffle():\n\u001b[0;32m      5\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m: \n\u001b[0;32m      6\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\calic\\Downloads\\imda_data_prep\\env\\lib\\site-packages\\datasets\\iterable_dataset.py:937\u001b[0m, in \u001b[0;36mIterableDataset.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    934\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter_pytorch(ex_iterable)\n\u001b[0;32m    935\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 937\u001b[0m \u001b[39mfor\u001b[39;00m key, example \u001b[39min\u001b[39;00m ex_iterable:\n\u001b[0;32m    938\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures:\n\u001b[0;32m    939\u001b[0m         \u001b[39m# `IterableDataset` automatically fills missing columns with None.\u001b[39;00m\n\u001b[0;32m    940\u001b[0m         \u001b[39m# This is done with `_apply_feature_types_on_example`.\u001b[39;00m\n\u001b[0;32m    941\u001b[0m         \u001b[39myield\u001b[39;00m _apply_feature_types_on_example(\n\u001b[0;32m    942\u001b[0m             example, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures, token_per_repo_id\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_token_per_repo_id\n\u001b[0;32m    943\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\calic\\Downloads\\imda_data_prep\\env\\lib\\site-packages\\datasets\\iterable_dataset.py:627\u001b[0m, in \u001b[0;36mBufferShuffledExamplesIterable.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39m# this is the shuffle buffer that we keep in memory\u001b[39;00m\n\u001b[0;32m    626\u001b[0m mem_buffer \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 627\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mex_iterable:\n\u001b[0;32m    628\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mem_buffer) \u001b[39m==\u001b[39m buffer_size:  \u001b[39m# if the buffer is full, pick and example from it\u001b[39;00m\n\u001b[0;32m    629\u001b[0m         i \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(indices_iterator)\n",
      "File \u001b[1;32mc:\\Users\\calic\\Downloads\\imda_data_prep\\env\\lib\\site-packages\\datasets\\iterable_dataset.py:138\u001b[0m, in \u001b[0;36mShuffledDataSourcesExamplesIterable.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    136\u001b[0m rng \u001b[39m=\u001b[39m deepcopy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerator)\n\u001b[0;32m    137\u001b[0m kwargs_with_shuffled_shards \u001b[39m=\u001b[39m _shuffle_gen_kwargs(rng, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs)\n\u001b[1;32m--> 138\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate_examples_fn(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs_with_shuffled_shards)\n",
      "File \u001b[1;32m~\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\loadingScript_imda_part3\\436704937271d38226d18f2dd0eba289043334e4babf98da5aa223df4ee365f4\\loadingScript_imda_part3.py:189\u001b[0m, in \u001b[0;36mNewDataset._generate_examples\u001b[1;34m(self, path_to_data, audio_ids, mics)\u001b[0m\n\u001b[0;32m    187\u001b[0m     intervalLength \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    188\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 189\u001b[0m     \u001b[39mif\u001b[39;00m (intervalLength \u001b[39m+\u001b[39m tg[\u001b[39m0\u001b[39;49m][i\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39mmaxTime\u001b[39m-\u001b[39mtg[\u001b[39m0\u001b[39m][i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mminTime) \u001b[39m<\u001b[39m INTERVAL_MAX_LENGTH:\n\u001b[0;32m    190\u001b[0m         i\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m    191\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\calic\\Downloads\\imda_data_prep\\textgrid\\textgrid\\textgrid.py:451\u001b[0m, in \u001b[0;36mIntervalTier.__getitem__\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, i):\n\u001b[1;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintervals[i]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from IPython.display import Audio, display\n",
    "\n",
    "index = 0\n",
    "for i in data.shuffle():\n",
    "    if index == 1: \n",
    "        break\n",
    "    display_data = i['audio']\n",
    "\n",
    "    print(f'sampling rate: {display_data[\"sampling_rate\"]}')\n",
    "    display(Audio(display_data[\"array\"], rate=display_data[\"sampling_rate\"]))\n",
    "    print(f'transcript: {i[\"transcript\"]}')\n",
    "    # print(f'gender: {i[\"gender\"]}')\n",
    "    # print(f'race: {i[\"race\"]}')\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "path_to_data = 'D:\\IMDA - National Speech Corpus\\PART1'\n",
    "mic = \"CHANNEL0\"\n",
    "speaker = '0001'\n",
    "metadata_path = os.path.join(path_to_data, \"DATA\", mic, \"SCRIPT\", mic[-1]+speaker+'*.TXT')\n",
    "print(metadata_path)\n",
    "script_list = glob.glob(metadata_path)\n",
    "print(script_list)\n",
    "d = {}\n",
    "for script in script_list:\n",
    "    line_num = 0\n",
    "    with open(script, encoding='utf-8-sig') as f:\n",
    "        for line in f:\n",
    "            if line_num == 0:\n",
    "                key = line.split(\"\\t\")[0]\n",
    "                line_num += 1\n",
    "\n",
    "            elif line_num == 1:\n",
    "                d[key] = line.strip()\n",
    "                line_num -= 1\n",
    "\n",
    "    break\n",
    "\n",
    "print(d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_path = r'D:\\IMDA - National Speech Corpus\\PART1\\DATA\\CHANNEL0\\WAVE\\SPEAKER0001.zip'\n",
    "from datasets.download import DownloadManager\n",
    "dl_manager = DownloadManager()\n",
    "if os.path.exists(archive_path):\n",
    "    audio_files = dl_manager.iter_archive(archive_path)\n",
    "    for path, f in audio_files:\n",
    "        print(path)\n",
    "        break\n",
    "else:\n",
    "    print('error')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring speaker information for train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "p1_speaker_df = pd.read_excel(\"./Speaker Information (Part 1).XLSX\", dtype={'SCD/PART1': object})\n",
    "p2_speaker_df = pd.read_excel(\"./Speaker Information (Part 2).XLSX\", dtype={'SCD/PART2': object})\n",
    "p1_speaker_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_speaker_df[\"SEX\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_speaker_df[\"ACC\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = p1_speaker_df[(p1_speaker_df[\"ACC\"]==\"CHINESE\") & (p1_speaker_df[\"SEX\"]==\"F\")]\n",
    "print(\"number of rows: \", len(X))\n",
    "X_train, X_test = train_test_split(X, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "print(\"number of rows in train: \",len(X_train))\n",
    "print(\"number of rows in test: \",len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genderlist = p1_speaker_df[\"SEX\"].unique()\n",
    "racelist = p1_speaker_df[\"ACC\"].unique()\n",
    "train_speaker_ids = []\n",
    "test_speaker_ids = []\n",
    "\n",
    "for gender in genderlist:\n",
    "    for race in racelist:\n",
    "        X = p1_speaker_df[(p1_speaker_df[\"ACC\"]==race) & (p1_speaker_df[\"SEX\"]==gender)]\n",
    "        X_train, X_test = train_test_split(X, test_size=0.3, random_state=42, shuffle=True)\n",
    "        train_speaker_ids.extend(X_train[\"SCD/PART1\"])\n",
    "        test_speaker_ids.extend(X_test[\"SCD/PART1\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_speaker_df.loc[p1_speaker_df[\"SCD/PART1\"]==\"0001\"].iloc[0][\"SEX\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83ff679c0ae51c3298408e270a36a6da442d58608875fa78406d64401a44cc70"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
